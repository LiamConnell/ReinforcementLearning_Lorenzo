{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import pandas.io.data as web\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SmallConfig(object):\n",
    "    \"\"\"Small config.\"\"\"\n",
    "    input_size = 5\n",
    "    output_size = 5\n",
    "    target_size = 1\n",
    "    num_steps = 20\n",
    "    num_layers = 2\n",
    "\n",
    "    num_samples = 2\n",
    "    learning_rate = 0.5\n",
    "    hidden_size = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, config, training=True):\n",
    "        #CONFIG\n",
    "        input_size = self.input_size =  config.input_size\n",
    "        output_size = self.output_size =  config.output_size\n",
    "            #target_size = self.target_size =  config.target_size\n",
    "        num_steps = self.num_steps =  config.num_steps\n",
    "        \n",
    "        num_samples = self.num_samples =  config.num_samples\n",
    "        learning_rate = self.learning_rate =  config.learning_rate\n",
    "        hidden_size = self.hidden_size =  config.hidden_size\n",
    "        num_layers = self.num_layers =  config.num_layers\n",
    "\n",
    "\n",
    "        # define placeholders \n",
    "        self.environment_ = tf.placeholder(tf.float32, [None, self.input_size])\n",
    "            #self.targets_ = tf.placeholder(tf.float32, [None,  self.target_size]) #shape?\n",
    "\n",
    "        #define cell\n",
    "        cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size, forget_bias=0.0)\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([cell] * config.num_layers)\n",
    "        cell = tf.nn.rnn_cell.InputProjectionWrapper(cell,  self.input_size)\n",
    "        cell = tf.nn.rnn_cell.OutputProjectionWrapper(cell, self.output_size)\n",
    "        self.cell = cell\n",
    "\n",
    "        #iterate through timesteps\n",
    "        self.LSTM_iter()     #asign self.final_state and self.outputs\n",
    "        \n",
    "        self.outputs_softmax = tf.nn.softmax(self.outputs)   # softmax[i, j] = exp(logits[i, j]) / sum(exp(logits[i]))\n",
    "        \n",
    "        self.sample_policy()\n",
    "        \n",
    "        self.get_status()\n",
    "        self.get_reward()\n",
    "\n",
    "        ones = tf.ones_like(self.training_target_cols)\n",
    "        gradient_ = tf.nn.sigmoid_cross_entropy_with_logits(self.training_target_cols, ones)\n",
    "        self.gradient = tf.transpose(tf.reshape(gradient_, [-1,2,num_samples]), [0,2,1]) #[?,5,2]\n",
    "        \n",
    "            #self.reward = tf.reduce_mean(self.targets_)\n",
    "        \n",
    "        self.cost = tf.mul(self.gradient , tf.expand_dims(self.reward, -1))\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(self.cost)\n",
    "\n",
    "        \n",
    "    def LSTM_iter(self):\n",
    "        self.outputs=[]\n",
    "        self.initial_state = self.cell.zero_state(1, tf.float32)    #batch size?\n",
    "        self.state = self.initial_state\n",
    "            \n",
    "        with tf.variable_scope(\"RNN\"):\n",
    "            for time_step in range(self.num_steps):   #####num_steps???\n",
    "                if time_step > 0: tf.get_variable_scope().reuse_variables()      #whats this?\n",
    "                inp = self.environment_[time_step,:]\n",
    "                inp = tf.reshape(inp, [1,-1])\n",
    "                (cell_output, self.state) = self.cell(inp, self.state)\n",
    "                self.outputs.append(cell_output) \n",
    "\n",
    "        self.final_state = self.state \n",
    "        self.outputs = tf.reshape(tf.concat(1, self.outputs), [-1, self.output_size])\n",
    "        \n",
    "    def sample_policy(self):\n",
    "        self.sample = tf.multinomial(tf.log(self.outputs), self.num_samples)\n",
    "        \n",
    "        relevant_target_column = {}\n",
    "        for sample_iter in range(self.num_samples):\n",
    "            sample_n = self.sample[:,sample_iter]\n",
    "            sample_mask = tf.cast(tf.reshape(tf.one_hot(sample_n, self.output_size), \n",
    "                                             [-1,self.output_size]), float32)\n",
    "            relevant_target_column[sample_iter] = tf.reduce_sum(\n",
    "                                                self.outputs_softmax * sample_mask,1)\n",
    "        self.training_target_cols = tf.concat(1, [tf.reshape(t, [-1,1]) for t in relevant_target_column.values()])\n",
    "        \n",
    "    def get_status(self):\n",
    "        self.status = None\n",
    "        return\n",
    "    def get_reward(self):\n",
    "        self.reward = None\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x10d9f6c88>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x10d9f6c88>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x10fd3fac8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x10fd3fac8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "# initialize variables to random values\n",
    "with tf.variable_scope(\"model\", reuse=None):\n",
    "    m = Model(config = SmallConfig)\n",
    "with tf.variable_scope(\"model\", reuse=True):\n",
    "    mvalid = Model(config = SmallConfig, training=False)\n",
    "sess.run(tf.initialize_all_variables())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = np.random.random([20,5])\n",
    "target = 2*(np.random.random([1,1]) - .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= -0.190774\n",
      "Epoch: 0004 cost= -0.192111\n",
      "Epoch: 0009 cost= -0.192357\n",
      "Epoch: 0016 cost= -0.190586\n",
      "Epoch: 0025 cost= -0.191192\n",
      "Epoch: 0036 cost= -0.192431\n",
      "Epoch: 0049 cost= -0.192226\n",
      "Epoch: 0064 cost= -0.192254\n",
      "Epoch: 0081 cost= -0.192042\n",
      "Epoch: 0100 cost= -0.192146\n",
      "Epoch: 0121 cost= -0.190722\n",
      "Epoch: 0144 cost= -0.191567\n",
      "Epoch: 0169 cost= -0.191888\n",
      "Epoch: 0196 cost= -0.191204\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    sess.run(m.optimizer, feed_dict={m.environment_: inputs, m.targets_: target})\n",
    "    if np.sqrt(epoch+1)%1== 0:\n",
    "        c = sess.run([ mvalid.cost], feed_dict={mvalid.environment_: inputs, mvalid.targets_: target})\n",
    "        c = np.mean(c)\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\",c, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    sess = tf.Session()\n",
    "    # initialize variables to random values\n",
    "    with tf.variable_scope(\"model\", reuse=None):\n",
    "        m = Model(config = SmallConfig)\n",
    "    with tf.variable_scope(\"model\", reuse=True):\n",
    "        mvalid = Model(config = SmallConfig, training=False)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# run optimizer on entire training data set many times\n",
    "train_size = train_ins.shape[0]\n",
    "for epoch in range(2000):\n",
    "    start = rng.randint(train_size-50)\n",
    "    batch_size = rng.randint(2,75)\n",
    "    end = min(train_size, start+batch_size)\n",
    "    \n",
    "    sess.run(m.optimizer, feed_dict={m.x: train_ins[start:end], m.y_: train_outs[start:end]})#.reshape(1,-1).T})\n",
    "    # every 1000 iterations record progress\n",
    "    if np.sqrt(epoch+1)%1== 0:\n",
    "        t,s, c = sess.run([ mvalid.total_return, mvalid.ann_vol, mvalid.costfn], feed_dict={mvalid.x: train_ins, mvalid.y_: train_outs})#.reshape(1,-1).T})\n",
    "        t = np.mean(t)\n",
    "        t = (1+t)**(1/6) -1\n",
    "        s = np.mean(s)\n",
    "        s = t/s\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\",c, \"total return=\", \"{:.9f}\".format(t), \n",
    "             \"sharpe=\", \"{:.9f}\".format(s))\n",
    "        #print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in sample results\n",
    "#init = tf.initialize_all_variables()\n",
    "#sess.run(init)\n",
    "d, t = sess.run([mvalid.daily_returns, mvalid.pos[0]], feed_dict={mvalid.x: train_ins, mvalid.y_: train_outs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
